{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22ea9b00-04a0-4a2d-bf66-fc1f2a29966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error, make_scorer, root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31e53c3b-3661-4270-b530-16d1d466d408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 10.9685\n",
      "Epoch 2/100, Loss: 0.9818\n",
      "Epoch 3/100, Loss: 0.4806\n",
      "Epoch 4/100, Loss: 0.3289\n",
      "Epoch 5/100, Loss: 0.2821\n",
      "Epoch 6/100, Loss: 0.2568\n",
      "Epoch 7/100, Loss: 0.2360\n",
      "Epoch 8/100, Loss: 0.2210\n",
      "Epoch 9/100, Loss: 0.2139\n",
      "Epoch 10/100, Loss: 0.1980\n",
      "Epoch 11/100, Loss: 0.1872\n",
      "Epoch 12/100, Loss: 0.1684\n",
      "Epoch 13/100, Loss: 0.1653\n",
      "Epoch 14/100, Loss: 0.1492\n",
      "Epoch 15/100, Loss: 0.1394\n",
      "Epoch 16/100, Loss: 0.1507\n",
      "Epoch 17/100, Loss: 0.1368\n",
      "Epoch 18/100, Loss: 0.1365\n",
      "Epoch 19/100, Loss: 0.1245\n",
      "Epoch 20/100, Loss: 0.1236\n",
      "Epoch 21/100, Loss: 0.1109\n",
      "Epoch 22/100, Loss: 0.0993\n",
      "Epoch 23/100, Loss: 0.0934\n",
      "Epoch 24/100, Loss: 0.0922\n",
      "Epoch 25/100, Loss: 0.0943\n",
      "Epoch 26/100, Loss: 0.0875\n",
      "Epoch 27/100, Loss: 0.0885\n",
      "Epoch 28/100, Loss: 0.0791\n",
      "Epoch 29/100, Loss: 0.0792\n",
      "Epoch 30/100, Loss: 0.0742\n",
      "Epoch 31/100, Loss: 0.0808\n",
      "Epoch 32/100, Loss: 0.0733\n",
      "Epoch 33/100, Loss: 0.0657\n",
      "Epoch 34/100, Loss: 0.0619\n",
      "Epoch 35/100, Loss: 0.0616\n",
      "Epoch 36/100, Loss: 0.0646\n",
      "Epoch 37/100, Loss: 0.0587\n",
      "Epoch 38/100, Loss: 0.0570\n",
      "Epoch 39/100, Loss: 0.0589\n",
      "Epoch 40/100, Loss: 0.0591\n",
      "Epoch 41/100, Loss: 0.0556\n",
      "Epoch 42/100, Loss: 0.0536\n",
      "Epoch 43/100, Loss: 0.0510\n",
      "Epoch 44/100, Loss: 0.0503\n",
      "Epoch 45/100, Loss: 0.0534\n",
      "Epoch 46/100, Loss: 0.0530\n",
      "Epoch 47/100, Loss: 0.0499\n",
      "Epoch 48/100, Loss: 0.0465\n",
      "Epoch 49/100, Loss: 0.0459\n",
      "Epoch 50/100, Loss: 0.0444\n",
      "Epoch 51/100, Loss: 0.0434\n",
      "Epoch 52/100, Loss: 0.0446\n",
      "Epoch 53/100, Loss: 0.0423\n",
      "Epoch 54/100, Loss: 0.0418\n",
      "Epoch 55/100, Loss: 0.0413\n",
      "Epoch 56/100, Loss: 0.0409\n",
      "Epoch 57/100, Loss: 0.0399\n",
      "Epoch 58/100, Loss: 0.0426\n",
      "Epoch 59/100, Loss: 0.0414\n",
      "Epoch 60/100, Loss: 0.0403\n",
      "Epoch 61/100, Loss: 0.0389\n",
      "Epoch 62/100, Loss: 0.0397\n",
      "Epoch 63/100, Loss: 0.0393\n",
      "Epoch 64/100, Loss: 0.0396\n",
      "Epoch 65/100, Loss: 0.0368\n",
      "Epoch 66/100, Loss: 0.0360\n",
      "Epoch 67/100, Loss: 0.0352\n",
      "Epoch 68/100, Loss: 0.0349\n",
      "Epoch 69/100, Loss: 0.0341\n",
      "Epoch 70/100, Loss: 0.0336\n",
      "Epoch 71/100, Loss: 0.0360\n",
      "Epoch 72/100, Loss: 0.0335\n",
      "Epoch 73/100, Loss: 0.0333\n",
      "Epoch 74/100, Loss: 0.0339\n",
      "Epoch 75/100, Loss: 0.0325\n",
      "Epoch 76/100, Loss: 0.0316\n",
      "Epoch 77/100, Loss: 0.0319\n",
      "Epoch 78/100, Loss: 0.0306\n",
      "Epoch 79/100, Loss: 0.0306\n",
      "Epoch 80/100, Loss: 0.0322\n",
      "Epoch 81/100, Loss: 0.0305\n",
      "Epoch 82/100, Loss: 0.0298\n",
      "Epoch 83/100, Loss: 0.0300\n",
      "Epoch 84/100, Loss: 0.0299\n",
      "Epoch 85/100, Loss: 0.0295\n",
      "Epoch 86/100, Loss: 0.0283\n",
      "Epoch 87/100, Loss: 0.0280\n",
      "Epoch 88/100, Loss: 0.0275\n",
      "Epoch 89/100, Loss: 0.0276\n",
      "Epoch 90/100, Loss: 0.0272\n",
      "Epoch 91/100, Loss: 0.0272\n",
      "Epoch 92/100, Loss: 0.0267\n",
      "Epoch 93/100, Loss: 0.0277\n",
      "Epoch 94/100, Loss: 0.0278\n",
      "Epoch 95/100, Loss: 0.0266\n",
      "Epoch 96/100, Loss: 0.0262\n",
      "Epoch 97/100, Loss: 0.0278\n",
      "Epoch 98/100, Loss: 0.0261\n",
      "Epoch 99/100, Loss: 0.0253\n",
      "Epoch 100/100, Loss: 0.0247\n",
      "\n",
      " TabTransformer Evaluation:\n",
      "MAE: 32667.395\n",
      "RMSE: 90722.945\n",
      "RÂ²: 0.9042181162473235\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Pollstar_all_genres.csv\")\n",
    "\n",
    "df = df[\n",
    "    (df['Genre'] != 'Family Entertainment') &\n",
    "    (df['Ticket Price Min USD'] > 0) &\n",
    "    (df['Ticket Price Min USD'] < df['Ticket Price Max USD'])\n",
    "].dropna()\n",
    "\n",
    "# add time info\n",
    "df['Event Date'] = pd.to_datetime(df['Event Date'])\n",
    "df['Year'] = df['Event Date'].dt.year\n",
    "df['Month'] = df['Event Date'].dt.month\n",
    "df['Weekday'] = df['Event Date'].dt.weekday\n",
    "df['Is_Weekend'] = df['Weekday'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "# Remove the extremely high values (top 0.5%)\n",
    "threshold = df[\"Avg. Gross USD\"].quantile(0.995)\n",
    "df = df[df[\"Avg. Gross USD\"] < threshold]\n",
    "\n",
    "target = \"Avg. Gross USD\"\n",
    "drop_cols = [\"Event Date\", \"Country\", \"Avg. Tickets Sold\", \"Avg. Capacity Sold\", \"Ticket Price Avg. USD\"]\n",
    "df = df.drop(columns=drop_cols)\n",
    "\n",
    "cat_cols = df.select_dtypes(include=\"object\").columns.tolist()\n",
    "num_cols = [col for col in df.columns if col not in cat_cols + [target]]\n",
    "\n",
    "# categorical variables Label encoding \n",
    "encoders = {}\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    encoders[col] = le\n",
    "\n",
    "# Target variable log1p conversion\n",
    "y = np.log1p(df[target].values.astype(np.float32))\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_num = scaler.fit_transform(df[num_cols].values.astype(np.float32))\n",
    "\n",
    "# classification features keep same\n",
    "X_cat = df[cat_cols].values.astype(np.int64)\n",
    "\n",
    "X_num_train, X_num_test, X_cat_train, X_cat_test, y_train, y_test = train_test_split(\n",
    "    X_num, X_cat, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# transfer to tensor\n",
    "X_num_train = torch.tensor(X_num_train)\n",
    "X_cat_train = torch.tensor(X_cat_train)\n",
    "y_train = torch.tensor(y_train).unsqueeze(1)\n",
    "\n",
    "X_num_test = torch.tensor(X_num_test)\n",
    "X_cat_test = torch.tensor(X_cat_test)\n",
    "y_test = torch.tensor(y_test).unsqueeze(1)\n",
    "\n",
    "train_dataset = TensorDataset(X_num_train, X_cat_train, y_train)\n",
    "test_dataset = TensorDataset(X_num_test, X_cat_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512)\n",
    "\n",
    "class TabTransformer(nn.Module):\n",
    "    def __init__(self, num_numeric, cat_dims, embed_dim=16):\n",
    "        super().__init__()\n",
    "        self.cat_embeds = nn.ModuleList([\n",
    "            nn.Embedding(dim, embed_dim) for dim in cat_dims\n",
    "        ])\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=embed_dim, nhead=4, dim_feedforward=128, dropout=0.1, activation='relu', batch_first=True\n",
    "            ), num_layers=2\n",
    "        )\n",
    "        self.numeric_proj = nn.Linear(num_numeric, embed_dim)\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(embed_dim * 2, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_num, x_cat):\n",
    "        embeds = [emb(x_cat[:, i]) for i, emb in enumerate(self.cat_embeds)]\n",
    "        x_cat_embed = torch.stack(embeds, dim=1)  # (B, T, D)\n",
    "        x_cat_trans = self.transformer(x_cat_embed).mean(dim=1)  # (B, D)\n",
    "\n",
    "        x_num_proj = self.numeric_proj(x_num)\n",
    "        x_combined = torch.cat([x_num_proj, x_cat_trans], dim=1)\n",
    "        return self.regressor(x_combined)\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "model = TabTransformer(\n",
    "    num_numeric=X_num.shape[1],\n",
    "    cat_dims=[df[col].nunique() for col in cat_cols]\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for x_num, x_cat, y in train_loader:\n",
    "        x_num, x_cat, y = x_num.to(device), x_cat.to(device), y.to(device)\n",
    "        preds = model(x_num, x_cat)\n",
    "        loss = loss_fn(preds, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "    print(f\"Epoch {epoch}/100, Loss: {np.mean(losses):.4f}\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds_list = []\n",
    "    y_list = []\n",
    "    for x_num, x_cat, y in test_loader:\n",
    "        x_num, x_cat = x_num.to(device), x_cat.to(device)\n",
    "        preds = model(x_num, x_cat).cpu().numpy()\n",
    "        preds_list.append(preds)\n",
    "        y_list.append(y.numpy())\n",
    "\n",
    "preds = np.expm1(np.vstack(preds_list))\n",
    "y_true = np.expm1(np.vstack(y_list))\n",
    "\n",
    "print(\"\\n TabTransformer Evaluation:\")\n",
    "print(\"MAE:\", mean_absolute_error(y_true, preds))\n",
    "print(\"RMSE:\", root_mean_squared_error(y_true, preds))\n",
    "print(\"RÂ²:\", r2_score(y_true, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfe8afe-a665-44b5-89bc-3fa55b6dd540",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
