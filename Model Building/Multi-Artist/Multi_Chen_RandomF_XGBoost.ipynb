{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4R43mLqcvRO",
        "outputId": "880b3dfd-09a2-4d7b-e24e-9f2206e41381"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "dataset_path = '/content/drive/MyDrive/combined_df.csv'\n",
        "df = pd.read_csv(dataset_path)\n",
        "train_df = df[\n",
        "        (df['Year'] >= 2020) &\n",
        "        (df['Headliner'].str.contains('\"', na=False)) &\n",
        "        (~df['Support'].isna()) &\n",
        "        (df['Genre'] != 'Family Entertainment')\n",
        "    ]\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "print(df.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EtqHhbtc5J-",
        "outputId": "6c029791-1afc-400a-b6fd-cb2551d8ee07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-b28503376d6d>:7: DtypeWarning: Columns (2,3,6,7,8,9,10,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(dataset_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of the dataset:\n",
            "   Event Date                              Headliner  \\\n",
            "0  2024-09-18                                  Creed   \n",
            "1  2024-09-14                                  Creed   \n",
            "2  2024-09-13  Bruce Springsteen & The E Street Band   \n",
            "3  2024-09-13                                  Creed   \n",
            "4  2024-09-13                Billy Joel, Rod Stewart   \n",
            "\n",
            "                          sp artist_name  \\\n",
            "0                                  Creed   \n",
            "1                                  Creed   \n",
            "2  Bruce Springsteen & The E Street Band   \n",
            "3                                  Creed   \n",
            "4                Billy Joel, Rod Stewart   \n",
            "\n",
            "                                     sp artist_genre  sp followers  \\\n",
            "0  ['alternative metal', 'nu metal', 'post-grunge...     3527070.0   \n",
            "1  ['alternative metal', 'nu metal', 'post-grunge...     3527070.0   \n",
            "2  ['heartland rock', 'mellow gold', 'permanent w...     6567386.0   \n",
            "3  ['alternative metal', 'nu metal', 'post-grunge...     3527070.0   \n",
            "4  ['album rock', 'classic rock', 'mellow gold', ...     6312751.0   \n",
            "\n",
            "   sp popularity                                yt name  \\\n",
            "0           74.0                                  Creed   \n",
            "1           74.0                                  Creed   \n",
            "2           79.0  Bruce Springsteen & The E Street Band   \n",
            "3           74.0                                  Creed   \n",
            "4           79.0                Billy Joel, Rod Stewart   \n",
            "\n",
            "              yt Channel ID           yt Title  \\\n",
            "0  UCP-tFf_VMQzhyeKMONL1KvQ              Creed   \n",
            "1  UCP-tFf_VMQzhyeKMONL1KvQ              Creed   \n",
            "2  UCcu7ANuD9J7hnTQCREqIc4Q  Bruce Springsteen   \n",
            "3  UCP-tFf_VMQzhyeKMONL1KvQ              Creed   \n",
            "4  UC0yYX8_4R-pITDGp0YC_Qfg      Rock Playlist   \n",
            "\n",
            "                                      yt Description  ...       Genre  \\\n",
            "0  Subscribe to Creed's Official Youtube Channel ...  ...  Pop / Rock   \n",
            "1  Subscribe to Creed's Official Youtube Channel ...  ...  Pop / Rock   \n",
            "2     Bruce Springsteen's official YouTube channel.   ...  Pop / Rock   \n",
            "3  Subscribe to Creed's Official Youtube Channel ...  ...  Pop / Rock   \n",
            "4                                                NaN  ...  Pop / Rock   \n",
            "\n",
            "   Avg. Tickets Sold  Avg. Gross USD  Avg. Event Capacity  Avg. Capacity Sold  \\\n",
            "0            20295.0       1228939.0              20295.0                100%   \n",
            "1            16308.0       1374174.0              16308.0                100%   \n",
            "2            39646.0       6556587.0              39646.0                100%   \n",
            "3            14995.0       1402969.0              14995.0                100%   \n",
            "4            44553.0       9676590.0              44553.0                100%   \n",
            "\n",
            "   Ticket Price Min USD  Ticket Price Max USD  Ticket Price Avg. USD  Month  \\\n",
            "0                  39.5                 225.0                  60.55      9   \n",
            "1                  39.5                 225.0                  84.26      9   \n",
            "2                  49.5                 299.5                 165.38      9   \n",
            "3                  39.5                 225.0                  93.56      9   \n",
            "4                  69.5                 349.5                 217.19      9   \n",
            "\n",
            "   day_of_week  \n",
            "0            2  \n",
            "1            5  \n",
            "2            4  \n",
            "3            4  \n",
            "4            4  \n",
            "\n",
            "[5 rows x 53 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nSummary statistics of the dataset:\")\n",
        "print(df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "N1wCWynbf3JA",
        "outputId": "1b76959f-3fde-4ac4-9a23-d961f0bf5d44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary statistics of the dataset:\n",
            "       sp followers  sp popularity  yt View Count  yt Subscriber Count  \\\n",
            "count  3.245600e+04   32456.000000   3.210200e+04         3.210200e+04   \n",
            "mean   2.498679e+06      51.025357   7.947109e+08         1.368386e+06   \n",
            "std    9.005023e+06      20.372168   3.018964e+09         5.633076e+06   \n",
            "min    0.000000e+00       0.000000   0.000000e+00         0.000000e+00   \n",
            "25%    6.217250e+04      40.000000   2.319628e+06         7.340000e+03   \n",
            "50%    3.271130e+05      53.000000   3.686581e+07         7.660000e+04   \n",
            "75%    1.490683e+06      65.000000   3.129296e+08         4.710000e+05   \n",
            "max    1.236853e+08     100.000000   6.104600e+10         3.210000e+08   \n",
            "\n",
            "       yt Video Count  Total population  Under 5 years population  \\\n",
            "count    32102.000000      3.249400e+04              32494.000000   \n",
            "mean       255.025263      8.631460e+05              50734.760448   \n",
            "std       1892.338983      1.569479e+06              95171.317352   \n",
            "min          0.000000      0.000000e+00                  0.000000   \n",
            "25%         32.000000      9.482600e+04               4942.000000   \n",
            "50%         99.000000      4.268770e+05              24883.000000   \n",
            "75%        228.000000      7.346030e+05              41522.000000   \n",
            "max     147757.000000      8.622467e+06             520467.000000   \n",
            "\n",
            "       5 to 9 years population  10 to 14 years population  \\\n",
            "count             32494.000000               32494.000000   \n",
            "mean              46775.165938               48785.864006   \n",
            "std               86410.304694               92184.448233   \n",
            "min                   0.000000                   0.000000   \n",
            "25%                4626.000000                5129.000000   \n",
            "50%               23220.000000               21482.000000   \n",
            "75%               37677.000000               36449.000000   \n",
            "max              469186.000000              501922.000000   \n",
            "\n",
            "       15 to 19 years population  ...  monthly_listeners  Number of Shows  \\\n",
            "count               32494.000000  ...       4.900000e+04    707628.000000   \n",
            "mean                49577.864529  ...       4.470017e+06         1.240002   \n",
            "std                 86235.886120  ...       1.001371e+07         6.961113   \n",
            "min                     0.000000  ...       1.000000e+00         1.000000   \n",
            "25%                  6303.000000  ...       1.715840e+05         1.000000   \n",
            "50%                 27687.000000  ...       1.121458e+06         1.000000   \n",
            "75%                 41331.000000  ...       3.919792e+06         1.000000   \n",
            "max                467114.000000  ...       2.564413e+08      5707.000000   \n",
            "\n",
            "       Avg. Tickets Sold  Avg. Gross USD  Avg. Event Capacity  \\\n",
            "count      707628.000000    7.076280e+05         7.076270e+05   \n",
            "mean         2118.999729    1.183563e+05         2.961416e+03   \n",
            "std          4085.119298    4.351130e+05         1.605620e+05   \n",
            "min             0.000000    5.000000e-01         1.000000e+01   \n",
            "25%           300.000000    5.550000e+03         5.000000e+02   \n",
            "50%           796.000000    2.108025e+04         1.148000e+03   \n",
            "75%          1927.000000    8.218125e+04         2.500000e+03   \n",
            "max        190200.000000    8.005627e+07         1.350076e+08   \n",
            "\n",
            "       Ticket Price Min USD  Ticket Price Max USD  Ticket Price Avg. USD  \\\n",
            "count         707628.000000          7.076280e+05          707621.000000   \n",
            "mean              26.759060          2.942475e+04              34.498404   \n",
            "std              213.909397          2.470720e+07              71.749407   \n",
            "min                0.000000         -1.495000e+02               0.010000   \n",
            "25%               15.000000          1.500000e+01              16.400000   \n",
            "50%               23.000000          3.000000e+01              26.510000   \n",
            "75%               35.000000          6.000000e+01              44.180000   \n",
            "max           156322.000000          2.078386e+10           44920.000000   \n",
            "\n",
            "               Month    day_of_week  \n",
            "count  707628.000000  707628.000000  \n",
            "mean        6.525454       3.516048  \n",
            "std         3.366555       1.743510  \n",
            "min         1.000000       0.000000  \n",
            "25%         4.000000       2.000000  \n",
            "50%         6.000000       4.000000  \n",
            "75%        10.000000       5.000000  \n",
            "max        12.000000       6.000000  \n",
            "\n",
            "[8 rows x 32 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display missing value counts for each column\n",
        "missing_values = df.isnull().sum()\n",
        "missing_percentage = (missing_values / len(df)) * 100\n",
        "print(\"Missing Values and Percentage:\")\n",
        "print(pd.DataFrame({'Missing Values': missing_values, 'Percentage': missing_percentage}).sort_values(by='Percentage', ascending=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCoBIYnAj83o",
        "outputId": "b48f944a-2b6b-408b-ebf3-2689452b0b85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing Values and Percentage:\n",
            "                                 Missing Values  Percentage\n",
            "yt Description                           682831   96.495758\n",
            "yt Published At                          675526   95.463436\n",
            "yt name                                  675526   95.463436\n",
            "yt Channel ID                            675526   95.463436\n",
            "yt Title                                 675526   95.463436\n",
            "yt View Count                            675526   95.463436\n",
            "yt Subscriber Count                      675526   95.463436\n",
            "yt Video Count                           675526   95.463436\n",
            "sp artist_name                           675172   95.413409\n",
            "sp artist_genre                          675172   95.413409\n",
            "sp followers                             675172   95.413409\n",
            "sp popularity                            675172   95.413409\n",
            "65 to 74 years population                675134   95.408039\n",
            "55 to 59 years population                675134   95.408039\n",
            "60 to 64 years population                675134   95.408039\n",
            "75 to 84 years population                675134   95.408039\n",
            "85 years and over population             675134   95.408039\n",
            "Median age                               675134   95.408039\n",
            "25 to 34 years population                675134   95.408039\n",
            "35 to 44 years population                675134   95.408039\n",
            "45 to 54 years population                675134   95.408039\n",
            "20 to 24 years population                675134   95.408039\n",
            "15 to 19 years population                675134   95.408039\n",
            "10 to 14 years population                675134   95.408039\n",
            "5 to 9 years population                  675134   95.408039\n",
            "Under 5 years population                 675134   95.408039\n",
            "Total population                         675134   95.408039\n",
            "monthly_listeners                        658628   93.075458\n",
            "headliner_monthly_listeners              597938   84.498918\n",
            "Support_Total_Monthly_Listeners          597938   84.498918\n",
            "Year                                     597938   84.498918\n",
            "Support                                  371754   52.535230\n",
            "Market                                    33306    4.706710\n",
            "Genre                                     32303    4.564969\n",
            "Promoter                                  15094    2.133042\n",
            "Company Type                               2901    0.409961\n",
            "Venue                                      1047    0.147959\n",
            "State                                        10    0.001413\n",
            "Ticket Price Avg. USD                         7    0.000989\n",
            "Avg. Event Capacity                           1    0.000141\n",
            "Ticket Price Min USD                          0    0.000000\n",
            "Ticket Price Max USD                          0    0.000000\n",
            "Avg. Capacity Sold                            0    0.000000\n",
            "Avg. Gross USD                                0    0.000000\n",
            "Month                                         0    0.000000\n",
            "Event Date                                    0    0.000000\n",
            "Avg. Tickets Sold                             0    0.000000\n",
            "Currency                                      0    0.000000\n",
            "Country                                       0    0.000000\n",
            "City                                          0    0.000000\n",
            "Number of Shows                               0    0.000000\n",
            "Headliner                                     0    0.000000\n",
            "day_of_week                                   0    0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling Missing Values"
      ],
      "metadata": {
        "id": "nFnxeWZyuCTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from geopy.geocoders import Nominatim\n",
        "\n",
        "# Define a function to infer 'State' based on 'City'\n",
        "def fill_state(city):\n",
        "    if pd.isnull(city) or city == \"Unknown\":\n",
        "        return \"Unknown\"\n",
        "    geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
        "    try:\n",
        "        # Attempt to fetch the location information using geopy\n",
        "        location = geolocator.geocode(city, timeout=10)\n",
        "        if location:\n",
        "            # Extract state information from the address\n",
        "            return location.address.split(',')[-3].strip()\n",
        "        else:\n",
        "            return \"Unknown\"\n",
        "    except:\n",
        "        # If geocoding fails, return 'Unknown'\n",
        "        return \"Unknown\"\n",
        "\n",
        "# Handle missing values in the 'State' column using the 'fill_state' function\n",
        "df['State'] = df.apply(lambda x: fill_state(x['City']) if pd.isnull(x['State']) else x['State'], axis=1)\n",
        "\n",
        "# Print to check remaining missing values in the 'State' column\n",
        "print(f\"Remaining missing values in 'State': {df['State'].isnull().sum()}\")\n",
        "\n",
        "# Fill missing values in categorical columns with 'Missing'\n",
        "categorical_cols = ['Support', 'Market', 'Genre', 'Promoter', 'Company Type', 'Venue']\n",
        "for col in categorical_cols:\n",
        "    df[col] = df[col].fillna(\"Missing\")\n",
        "\n",
        "# Fill missing values in numerical columns with mean\n",
        "df['Ticket Price Avg. USD'] = df['Ticket Price Avg. USD'].fillna(df['Ticket Price Avg. USD'].mean())\n",
        "df['Avg. Event Capacity'] = df['Avg. Event Capacity'].fillna(df['Avg. Event Capacity'].mean())\n",
        "\n",
        "# Check if any missing values remain in the dataset\n",
        "print(\"Remaining missing values in the dataset:\")\n",
        "print(df.isnull().sum())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qa-BrvJ7mMic",
        "outputId": "40ba4644-d146-4d46-8a9c-cffce76a1a63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Remaining missing values in 'State': 0\n",
            "Remaining missing values in the dataset:\n",
            "Event Date                              0\n",
            "Headliner                               0\n",
            "sp artist_name                     675172\n",
            "sp artist_genre                    675172\n",
            "sp followers                       675172\n",
            "sp popularity                      675172\n",
            "yt name                            675526\n",
            "yt Channel ID                      675526\n",
            "yt Title                           675526\n",
            "yt Description                     682831\n",
            "yt Published At                    675526\n",
            "yt View Count                      675526\n",
            "yt Subscriber Count                675526\n",
            "yt Video Count                     675526\n",
            "Total population                   675134\n",
            "Under 5 years population           675134\n",
            "5 to 9 years population            675134\n",
            "10 to 14 years population          675134\n",
            "15 to 19 years population          675134\n",
            "20 to 24 years population          675134\n",
            "25 to 34 years population          675134\n",
            "35 to 44 years population          675134\n",
            "45 to 54 years population          675134\n",
            "55 to 59 years population          675134\n",
            "60 to 64 years population          675134\n",
            "65 to 74 years population          675134\n",
            "75 to 84 years population          675134\n",
            "85 years and over population       675134\n",
            "Median age                         675134\n",
            "Year                               597938\n",
            "headliner_monthly_listeners        597938\n",
            "Support_Total_Monthly_Listeners    597938\n",
            "monthly_listeners                  658628\n",
            "Number of Shows                         0\n",
            "Support                                 0\n",
            "Venue                                   0\n",
            "City                                    0\n",
            "State                                   0\n",
            "Country                                 0\n",
            "Market                                  0\n",
            "Company Type                            0\n",
            "Currency                                0\n",
            "Promoter                                0\n",
            "Genre                                   0\n",
            "Avg. Tickets Sold                       0\n",
            "Avg. Gross USD                          0\n",
            "Avg. Event Capacity                     0\n",
            "Avg. Capacity Sold                      0\n",
            "Ticket Price Min USD                    0\n",
            "Ticket Price Max USD                    0\n",
            "Ticket Price Avg. USD                   0\n",
            "Month                                   0\n",
            "day_of_week                             0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Convert 'Event Date' to datetime format and extract features\n",
        "df['Event Date'] = pd.to_datetime(df['Event Date'])\n",
        "\n",
        "# Feature engineering: extract useful time-related features\n",
        "df['Year'] = df['Event Date'].dt.year\n",
        "df['Month'] = df['Event Date'].dt.month\n",
        "df['Day'] = df['Event Date'].dt.day\n",
        "df['Day_of_Week'] = df['Event Date'].dt.dayofweek  # 0 = Monday, 6 = Sunday\n",
        "df['Day_of_Year'] = df['Event Date'].dt.dayofyear\n",
        "df['Is_Weekend'] = (df['Day_of_Week'] >= 5).astype(int)  # 1 for Saturday/Sunday\n",
        "\n",
        "# Create interaction features between price and capacity\n",
        "df['Price_Range'] = df['Ticket Price Max USD'] - df['Ticket Price Min USD']\n",
        "df['Gross_Per_Capacity'] = df['Avg. Gross USD'] / df['Avg. Event Capacity']\n",
        "\n",
        "# Handle infinite or NaN values created during feature engineering\n",
        "df['Gross_Per_Capacity'] = df['Gross_Per_Capacity'].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "\n",
        "# Scale/normalize numerical features\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Select numerical columns for normalization\n",
        "numerical_features = [\n",
        "    'Avg. Gross USD',\n",
        "    'Ticket Price Avg. USD',\n",
        "    'Avg. Event Capacity',\n",
        "    'Price_Range',\n",
        "    'Gross_Per_Capacity'\n",
        "]\n",
        "\n",
        "# Normalize the numerical features\n",
        "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
        "\n",
        "# Drop the original 'Event Date' column after processing\n",
        "df = df.drop(columns=['Event Date'])\n",
        "df = df.drop(columns=['day_of_week'])\n",
        "# Final check: View the processed data\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "671t55DI8U5d",
        "outputId": "ac1d14bc-e278-4554-eba6-bdf65afb6e1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                               Headliner  \\\n",
            "0                                  Creed   \n",
            "1                                  Creed   \n",
            "2  Bruce Springsteen & The E Street Band   \n",
            "3                                  Creed   \n",
            "4                Billy Joel, Rod Stewart   \n",
            "\n",
            "                          sp artist_name  \\\n",
            "0                                  Creed   \n",
            "1                                  Creed   \n",
            "2  Bruce Springsteen & The E Street Band   \n",
            "3                                  Creed   \n",
            "4                Billy Joel, Rod Stewart   \n",
            "\n",
            "                                     sp artist_genre  sp followers  \\\n",
            "0  ['alternative metal', 'nu metal', 'post-grunge...     3527070.0   \n",
            "1  ['alternative metal', 'nu metal', 'post-grunge...     3527070.0   \n",
            "2  ['heartland rock', 'mellow gold', 'permanent w...     6567386.0   \n",
            "3  ['alternative metal', 'nu metal', 'post-grunge...     3527070.0   \n",
            "4  ['album rock', 'classic rock', 'mellow gold', ...     6312751.0   \n",
            "\n",
            "   sp popularity                                yt name  \\\n",
            "0           74.0                                  Creed   \n",
            "1           74.0                                  Creed   \n",
            "2           79.0  Bruce Springsteen & The E Street Band   \n",
            "3           74.0                                  Creed   \n",
            "4           79.0                Billy Joel, Rod Stewart   \n",
            "\n",
            "              yt Channel ID           yt Title  \\\n",
            "0  UCP-tFf_VMQzhyeKMONL1KvQ              Creed   \n",
            "1  UCP-tFf_VMQzhyeKMONL1KvQ              Creed   \n",
            "2  UCcu7ANuD9J7hnTQCREqIc4Q  Bruce Springsteen   \n",
            "3  UCP-tFf_VMQzhyeKMONL1KvQ              Creed   \n",
            "4  UC0yYX8_4R-pITDGp0YC_Qfg      Rock Playlist   \n",
            "\n",
            "                                      yt Description  \\\n",
            "0  Subscribe to Creed's Official Youtube Channel ...   \n",
            "1  Subscribe to Creed's Official Youtube Channel ...   \n",
            "2     Bruce Springsteen's official YouTube channel.    \n",
            "3  Subscribe to Creed's Official Youtube Channel ...   \n",
            "4                                                NaN   \n",
            "\n",
            "               yt Published At  ...  Ticket Price Min USD  \\\n",
            "0         2009-03-30T21:30:11Z  ...                  39.5   \n",
            "1         2009-03-30T21:30:11Z  ...                  39.5   \n",
            "2         2006-04-01T18:32:28Z  ...                  49.5   \n",
            "3         2009-03-30T21:30:11Z  ...                  39.5   \n",
            "4  2024-02-28T03:11:06.872221Z  ...                  69.5   \n",
            "\n",
            "   Ticket Price Max USD  Ticket Price Avg. USD  Month  Day  Day_of_Week  \\\n",
            "0                 225.0               0.363094      9   18            2   \n",
            "1                 225.0               0.693551      9   14            5   \n",
            "2                 299.5               1.824159      9   13            4   \n",
            "3                 225.0               0.823170      9   13            4   \n",
            "4                 349.5               2.546260      9   13            4   \n",
            "\n",
            "   Day_of_Year  Is_Weekend  Price_Range  Gross_Per_Capacity  \n",
            "0          262           0    -0.001182            1.249385  \n",
            "1          258           1    -0.001182            2.119206  \n",
            "2          257           0    -0.001180            5.094955  \n",
            "3          257           0    -0.001182            2.460335  \n",
            "4          257           0    -0.001179            6.995812  \n",
            "\n",
            "[5 rows x 57 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distribution-balanced Stratified Cross-Validation"
      ],
      "metadata": {
        "id": "2K8EoJ6E-svu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def dbscv(x: np.array, y: np.array, params: dict) -> (list, list, list, list):\n",
        "    \"\"\"\n",
        "    Distribution-balanced stratified cross-validation (DBSCV) splitting method.\n",
        "\n",
        "    Parameters:\n",
        "    - x: np.array, feature matrix of shape (N, M)\n",
        "    - y: np.array, labels array of shape (N,)\n",
        "    - params: dict, should contain 'K' (number of folds)\n",
        "\n",
        "    Returns:\n",
        "    - x_fit: list of np.array, training feature sets for each fold\n",
        "    - x_val: list of np.array, validation feature sets for each fold\n",
        "    - y_fit: list of np.array, training label sets for each fold\n",
        "    - y_val: list of np.array, validation label sets for each fold\n",
        "    \"\"\"\n",
        "    k = params.get('K', 5)  # Number of folds, default is 5\n",
        "    N, M = x.shape  # N: number of samples, M: number of features\n",
        "    classes = np.unique(y)  # Unique class labels\n",
        "\n",
        "    # Initialize reference feature vector X0 (zeros for continuous attributes)\n",
        "    X0 = np.zeros(M)\n",
        "\n",
        "    # Initialize folds: T[0] corresponds to fold 1\n",
        "    T = [[] for _ in range(k)]\n",
        "\n",
        "    # List to hold remaining samples after main distribution\n",
        "    L_r = []\n",
        "\n",
        "    # For each class, construct the sorted list L_i\n",
        "    for c in classes:\n",
        "        # Indices of samples with class label c\n",
        "        S_i = np.where(y == c)[0].tolist()\n",
        "        Li = []\n",
        "        last_sample = X0\n",
        "\n",
        "        # Step (2): Sort the cases of each class\n",
        "        while S_i:\n",
        "            # Extract samples of class c\n",
        "            samples = x[S_i, :]\n",
        "            # Compute Euclidean distances to the last sample\n",
        "            distances = np.linalg.norm(samples - last_sample, axis=1)\n",
        "            # Find the sample with the minimum distance\n",
        "            min_idx = np.argmin(distances)\n",
        "            sample_index = S_i[min_idx]\n",
        "            # Add to the sorted list Li\n",
        "            Li.append(sample_index)\n",
        "            # Update last_sample and remove the selected sample from S_i\n",
        "            last_sample = x[sample_index]\n",
        "            S_i.pop(min_idx)\n",
        "\n",
        "        # Step (3): Partition each Li into k folds\n",
        "        idx = 0\n",
        "        while idx + k <= len(Li):\n",
        "            for j in range(k):\n",
        "                index = Li[idx + j]\n",
        "                T[j].append(index)\n",
        "            idx += k\n",
        "\n",
        "        # Collect remaining samples to L_r\n",
        "        Li_remain = Li[idx:]\n",
        "        if Li_remain:\n",
        "            L_r.extend(Li_remain)\n",
        "\n",
        "    # Distribute remaining samples in L_r into folds T_j\n",
        "    for i, index in enumerate(L_r):\n",
        "        T[i % k].append(index)\n",
        "\n",
        "    # Prepare training and validation sets for each fold\n",
        "    x_fit = []\n",
        "    x_val = []\n",
        "    y_fit = []\n",
        "    y_val = []\n",
        "\n",
        "    indices_all = np.arange(N)\n",
        "\n",
        "    for j in range(k):\n",
        "        val_indices = np.array(T[j])\n",
        "        train_indices = np.setdiff1d(indices_all, val_indices)\n",
        "\n",
        "        x_val.append(x[val_indices])\n",
        "        y_val.append(y[val_indices])\n",
        "\n",
        "        x_fit.append(x[train_indices])\n",
        "        y_fit.append(y[train_indices])\n",
        "\n",
        "    return x_fit, x_val, y_fit, y_val\n"
      ],
      "metadata": {
        "id": "0FLqXXn2-sKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare Dataset"
      ],
      "metadata": {
        "id": "txtqwsus-56L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "categorical_features = ['Headliner', 'Support', 'Market', 'Genre', 'Promoter', 'Company Type', 'Venue', 'City', 'State']\n",
        "numerical_features = ['Avg. Gross USD', 'Ticket Price Avg. USD', 'Avg. Event Capacity',\n",
        "                      'Price_Range', 'Gross_Per_Capacity', 'Year', 'Month', 'Day',\n",
        "                      'Day_of_Year', 'Is_Weekend']\n",
        "# Encode categorical features with LabelEncoder\n",
        "label_encoders = {}\n",
        "for col in categorical_features:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col].astype(str))\n",
        "    label_encoders[col] = le  # Save the encoder for later use\n",
        "\n",
        "# Concatenate encoded categorical features with numerical features\n",
        "final_df = df[numerical_features + categorical_features]\n",
        "\n",
        "# Ensure no missing values remain in the final dataset\n",
        "final_df = final_df.fillna(0)\n",
        "\n",
        "# Features (X) and target (y)\n",
        "X = final_df.drop(columns=['Avg. Gross USD']).values  # Drop the target column from features\n",
        "y = final_df['Avg. Gross USD'].values                # Target variable\n",
        "\n"
      ],
      "metadata": {
        "id": "SdC4zufy-33o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters for DBSCV\n",
        "params = {'K': 5}  # Number of folds\n",
        "\n",
        "# Apply DBSCV to the dataset\n",
        "x_fit, x_val, y_fit, y_val = dbscv(X, y, params)"
      ],
      "metadata": {
        "id": "2UeiJMi5Atxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Initialize Random Forest\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train and evaluate using DBSCV splits\n",
        "rf_scores = []  # To store evaluation metrics for each fold\n",
        "\n",
        "for i in range(len(x_fit)):\n",
        "    # Train the model on training set\n",
        "    rf_model.fit(x_fit[i], y_fit[i])\n",
        "\n",
        "    # Predict on validation set\n",
        "    predictions = rf_model.predict(x_val[i])\n",
        "\n",
        "    # Calculate metrics\n",
        "    mse = mean_squared_error(y_val[i], predictions)\n",
        "    r2 = r2_score(y_val[i], predictions)\n",
        "    rf_scores.append((mse, r2))\n",
        "\n",
        "# Print evaluation results for each fold\n",
        "for fold, (mse, r2) in enumerate(rf_scores, 1):\n",
        "    print(f\"Random Forest - Fold {fold}: MSE = {mse:.4f}, R^2 = {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "596WKu7TDpad",
        "outputId": "aba26232-8175-46eb-ed14-9e84b8336369"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest - Fold 1: MSE = 0.0447, R^2 = 0.9537\n",
            "Random Forest - Fold 2: MSE = 0.0201, R^2 = 0.9802\n",
            "Random Forest - Fold 3: MSE = 0.0694, R^2 = 0.9397\n",
            "Random Forest - Fold 4: MSE = 0.0056, R^2 = 0.9939\n",
            "Random Forest - Fold 5: MSE = 0.0031, R^2 = 0.9968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "\n",
        "# Initialize XGBoost\n",
        "xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42, objective='reg:squarederror')\n",
        "\n",
        "# Train and evaluate using DBSCV splits\n",
        "xgb_scores = []  # To store evaluation metrics for each fold\n",
        "\n",
        "for i in range(len(x_fit)):\n",
        "    # Train the model on training set\n",
        "    xgb_model.fit(x_fit[i], y_fit[i])\n",
        "\n",
        "    # Predict on validation set\n",
        "    predictions = xgb_model.predict(x_val[i])\n",
        "\n",
        "    # Calculate metrics\n",
        "    mse = mean_squared_error(y_val[i], predictions)\n",
        "    r2 = r2_score(y_val[i], predictions)\n",
        "    xgb_scores.append((mse, r2))\n",
        "\n",
        "# Print evaluation results for each fold\n",
        "for fold, (mse, r2) in enumerate(xgb_scores, 1):\n",
        "    print(f\"XGBoost - Fold {fold}: MSE = {mse:.4f}, R^2 = {r2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNz09OK9DrHK",
        "outputId": "afd1af60-75cb-4d44-b26d-7f394b3deb93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost - Fold 1: MSE = 0.0512, R^2 = 0.9469\n",
            "XGBoost - Fold 2: MSE = 0.1158, R^2 = 0.8857\n",
            "XGBoost - Fold 3: MSE = 0.1835, R^2 = 0.8404\n",
            "XGBoost - Fold 4: MSE = 0.0723, R^2 = 0.9223\n",
            "XGBoost - Fold 5: MSE = 0.0466, R^2 = 0.9506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rmse = np.sqrt(mse)\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aac5F3xRY3TK",
        "outputId": "98e769c3-b735-4ee3-a252-0702359862ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE): 0.2159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer, mean_squared_error, r2_score\n",
        "\n",
        "# Define the parameter grid for Random Forest\n",
        "rf_param_grid = {\n",
        "    'n_estimators': [100, 200, 300],       # Number of trees\n",
        "    'max_depth': [10, 20, None],          # Depth of each tree\n",
        "    'min_samples_split': [2, 5, 10],      # Minimum samples to split a node\n",
        "    'min_samples_leaf': [1, 2, 4]         # Minimum samples in a leaf node\n",
        "}\n",
        "\n",
        "# Custom scoring metrics\n",
        "scoring = {\n",
        "    'MSE': make_scorer(mean_squared_error, greater_is_better=False),\n",
        "    'R2': make_scorer(r2_score)\n",
        "}\n",
        "\n",
        "# Initialize the Random Forest model\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Perform GridSearchCV\n",
        "rf_grid_search = GridSearchCV(\n",
        "    estimator=rf_model,\n",
        "    param_grid=rf_param_grid,\n",
        "    scoring=scoring,\n",
        "    refit='R2',  # Optimize for R2 score\n",
        "    cv=list(zip(x_fit, y_fit, x_val, y_val)),  # Use DBSCV splits\n",
        "    verbose=2,\n",
        "    n_jobs=-1  # Use all available CPU cores\n",
        ")\n",
        "\n",
        "# Fit the GridSearchCV model\n",
        "rf_grid_search.fit(X, y)\n",
        "\n",
        "# Best parameters and scores\n",
        "print(\"Best Parameters for Random Forest:\", rf_grid_search.best_params_)\n",
        "print(\"Best R^2 Score for Random Forest:\", rf_grid_search.best_score_)\n",
        "\n"
      ],
      "metadata": {
        "id": "I4HQQSyUCsTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade scikit-learn xgboost\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qy18hA21Z1nN",
        "outputId": "1a0abf7b-8799-4a09-de29-03b76a9654c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.3)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer, mean_squared_error, r2_score\n",
        "\n",
        "# Define the parameter grid for XGBoost\n",
        "xgb_param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 6, 10],\n",
        "    'min_child_weight': [1, 3, 5],\n",
        "    'subsample': [0.6, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
        "}\n",
        "\n",
        "# Initialize XGBoost\n",
        "xgb_model = XGBRegressor(random_state=42, objective='reg:squarederror')\n",
        "\n",
        "scoring = {\n",
        "    'MSE': make_scorer(mean_squared_error, greater_is_better=False),\n",
        "    'R2': make_scorer(r2_score)\n",
        "}\n",
        "# Perform GridSearchCV\n",
        "xgb_grid_search = GridSearchCV(\n",
        "    estimator=xgb_model,\n",
        "    param_grid=xgb_param_grid,\n",
        "    scoring=scoring,\n",
        "    refit='R2',  # Optimize for R^2 score\n",
        "    cv=5,        # Number of cross-validation folds\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "xgb_grid_search.fit(X, y)\n",
        "\n",
        "# Best parameters and scores\n",
        "print(\"Best Parameters for XGBoost:\", xgb_grid_search.best_params_)\n",
        "print(\"Best R^2 Score for XGBoost:\", xgb_grid_search.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "oalzYD97C4QH",
        "outputId": "78815980-9d48-4806-dc44-2397bbe43ee1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'super' object has no attribute '__sklearn_tags__'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-5228e019a65d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mxgb_grid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Best parameters and scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mrouted_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_routed_params_for_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m         \u001b[0mcv_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m         \u001b[0mn_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_orig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mrouted_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mis_classifier\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m   1235\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_estimator_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"classifier\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1237\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"classifier\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_tags.py\u001b[0m in \u001b[0;36mget_tags\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mklass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmro\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"__sklearn_tags__\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m                 \u001b[0msklearn_tags_provider\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__sklearn_tags__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m                 \u001b[0mclass_order\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;34m\"_more_tags\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m__sklearn_tags__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__sklearn_tags__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__sklearn_tags__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m         \u001b[0mtags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"regressor\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m         \u001b[0mtags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregressor_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRegressorTags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'super' object has no attribute '__sklearn_tags__'"
          ]
        }
      ]
    }
  ]
}