{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and add any columns by preprocessing the dataframe or merging with others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, RepeatedKFold\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\AppData\\Local\\Temp\\ipykernel_1380\\9792566.py:1: DtypeWarning: Columns (2,3,6,7,8,9,10,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('data/combined_df.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event Date</th>\n",
       "      <th>Headliner</th>\n",
       "      <th>sp artist_name</th>\n",
       "      <th>sp artist_genre</th>\n",
       "      <th>sp followers</th>\n",
       "      <th>sp popularity</th>\n",
       "      <th>yt name</th>\n",
       "      <th>yt Channel ID</th>\n",
       "      <th>yt Title</th>\n",
       "      <th>yt Description</th>\n",
       "      <th>...</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Avg. Tickets Sold</th>\n",
       "      <th>Avg. Gross USD</th>\n",
       "      <th>Avg. Event Capacity</th>\n",
       "      <th>Avg. Capacity Sold</th>\n",
       "      <th>Ticket Price Min USD</th>\n",
       "      <th>Ticket Price Max USD</th>\n",
       "      <th>Ticket Price Avg. USD</th>\n",
       "      <th>Month</th>\n",
       "      <th>day_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2024-08-31</td>\n",
       "      <td>\"Summer of '99 and Beyond Festival\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Multi-Genre</td>\n",
       "      <td>23332.0</td>\n",
       "      <td>1441577.0</td>\n",
       "      <td>23332.0</td>\n",
       "      <td>100%</td>\n",
       "      <td>39.5</td>\n",
       "      <td>159.5</td>\n",
       "      <td>61.79</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2024-08-31</td>\n",
       "      <td>\"Reggae Fest Massive\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Reggae</td>\n",
       "      <td>12791.0</td>\n",
       "      <td>1418343.5</td>\n",
       "      <td>12791.0</td>\n",
       "      <td>100%</td>\n",
       "      <td>43.5</td>\n",
       "      <td>343.5</td>\n",
       "      <td>110.89</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2024-08-30</td>\n",
       "      <td>\"DC Jazz Festival\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Multi-Genre</td>\n",
       "      <td>2394.0</td>\n",
       "      <td>252568.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>95%</td>\n",
       "      <td>55.2</td>\n",
       "      <td>299.0</td>\n",
       "      <td>105.50</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Event Date                            Headliner sp artist_name  \\\n",
       "100 2024-08-31  \"Summer of '99 and Beyond Festival\"            NaN   \n",
       "117 2024-08-31                \"Reggae Fest Massive\"            NaN   \n",
       "133 2024-08-30                   \"DC Jazz Festival\"            NaN   \n",
       "\n",
       "    sp artist_genre  sp followers  sp popularity yt name yt Channel ID  \\\n",
       "100             NaN           NaN            NaN     NaN           NaN   \n",
       "117             NaN           NaN            NaN     NaN           NaN   \n",
       "133             NaN           NaN            NaN     NaN           NaN   \n",
       "\n",
       "    yt Title yt Description  ...        Genre  Avg. Tickets Sold  \\\n",
       "100      NaN            NaN  ...  Multi-Genre            23332.0   \n",
       "117      NaN            NaN  ...       Reggae            12791.0   \n",
       "133      NaN            NaN  ...  Multi-Genre             2394.0   \n",
       "\n",
       "     Avg. Gross USD  Avg. Event Capacity  Avg. Capacity Sold  \\\n",
       "100       1441577.0              23332.0                100%   \n",
       "117       1418343.5              12791.0                100%   \n",
       "133        252568.0               2500.0                 95%   \n",
       "\n",
       "     Ticket Price Min USD  Ticket Price Max USD  Ticket Price Avg. USD  Month  \\\n",
       "100                  39.5                 159.5                  61.79      8   \n",
       "117                  43.5                 343.5                 110.89      8   \n",
       "133                  55.2                 299.0                 105.50      8   \n",
       "\n",
       "     day_of_week  \n",
       "100            5  \n",
       "117            5  \n",
       "133            4  \n",
       "\n",
       "[3 rows x 53 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/combined_df.csv')\n",
    "data = data[\n",
    "    (data['Year'] >= 2020) &\n",
    "    (data['Headliner'].str.contains('\"', na=False)) &\n",
    "    (~data['Support'].isna()) &\n",
    "    (data['Genre'] != 'Family Entertainment')\n",
    "  ]\n",
    "data['Event Date'] = pd.to_datetime(data['Event Date'])\n",
    "data['day_of_week'] = data['Event Date'].dt.day_of_week\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing sp data: 2258 rows\n",
      "Missing population data: 2258 rows\n",
      "Missing yt data: 2265 rows\n",
      "Missing monthly listeners data: 213 rows\n"
     ]
    }
   ],
   "source": [
    "# check for missing values\n",
    "print(f'Missing sp data: {sum(data[\"sp followers\"].isna())} rows')\n",
    "print(f'Missing population data: {sum(data[\"Total population\"].isna())} rows')\n",
    "print(f'Missing yt data: {sum(data[\"yt Subscriber Count\"].isna())} rows')\n",
    "print(f'Missing monthly listeners data: {sum(data[\"monthly_listeners\"].isna())} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_markets = data['Market'].value_counts().iloc[:20].index\n",
    "one_hot_encoded = pd.get_dummies(data['Market'])\n",
    "one_hot_encoded = one_hot_encoded[top_20_markets]\n",
    "data = data.join(one_hot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Avg. Event Capacity',\n",
    "            'Ticket Price Min USD', \n",
    "            'Ticket Price Max USD',\n",
    "            'Year',\n",
    "            'monthly_listeners',\n",
    "            'Month',\n",
    "            'day_of_week'] + list(top_20_markets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[features]\n",
    "y = data['Avg. Gross USD']\n",
    "X = X.dropna()\n",
    "y = y[X.index]\n",
    "# no need to split train/test (since we don’t have that much rows) —> can just take the average of the metrics from cross_val_score\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Cross-Validation Performance:\n",
      "Cross-Validation RMSE: Mean = 795801.0984544507\n",
      "Cross-Validation MAE: Mean = 254797.89878060442\n",
      "Cross-Validation R^2: Mean = -1.1400147186132303\n"
     ]
    }
   ],
   "source": [
    "linear_model = LinearRegression()\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=10)\n",
    "\n",
    "cv_rmse = np.sqrt(-cross_val_score(linear_model, X, y, cv=rkf, scoring='neg_mean_squared_error'))\n",
    "cv_mae = -cross_val_score(linear_model, X, y, cv=rkf, scoring='neg_mean_absolute_error')\n",
    "cv_r2 = cross_val_score(linear_model, X, y, cv=rkf, scoring='r2')\n",
    "\n",
    "print(\"Linear Regression Cross-Validation Performance:\")\n",
    "print(\"Cross-Validation RMSE: Mean =\", cv_rmse.mean())\n",
    "print(\"Cross-Validation MAE: Mean =\", cv_mae.mean())\n",
    "print(\"Cross-Validation R^2: Mean =\", cv_r2.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default random forest model\n",
    "random_forest_model = RandomForestRegressor(n_estimators=100)\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=10)\n",
    "\n",
    "cv_rmse = np.sqrt(-cross_val_score(random_forest_model, X, y, cv=rkf, scoring='neg_mean_squared_error'))\n",
    "cv_mae = -cross_val_score(random_forest_model, X, y, cv=rkf, scoring='neg_mean_absolute_error')\n",
    "cv_r2 = cross_val_score(random_forest_model, X, y, cv=rkf, scoring='r2')\n",
    "\n",
    "print(\"Random Forest Regressor Cross-Validation Performance:\")\n",
    "print(\"Cross-Validation RMSE: Mean =\", cv_rmse.mean())\n",
    "print(\"Cross-Validation MAE: Mean =\", cv_mae.mean())\n",
    "print(\"Cross-Validation R^2: Mean =\", cv_r2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random_forest_model = RandomForestRegressor(n_estimators=100)\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Best cross-validated R^2: 0.7838963373643677\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5],\n",
    "    'max_features': ['sqrt', 'log2', 1.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=best_random_forest_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  \n",
    "    scoring='r2',\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validated R^2:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Random Forest Regressor Cross-Validation Performance:\n",
      "Cross-Validation RMSE: Mean = 387911.75691995444\n",
      "Cross-Validation MAE: Mean = 131839.5170897241\n",
      "Cross-Validation R^2: Mean = 0.7980930315260997\n"
     ]
    }
   ],
   "source": [
    "best_random_forest_model = grid_search.best_estimator_\n",
    "\n",
    "cv_rmse = np.sqrt(-cross_val_score(best_random_forest_model, X, y, cv=rkf, scoring='neg_mean_squared_error'))\n",
    "cv_mae = -cross_val_score(best_random_forest_model, X, y, cv=rkf, scoring='neg_mean_absolute_error')\n",
    "cv_r2 = cross_val_score(best_random_forest_model, X, y, cv=rkf, scoring='r2')\n",
    "\n",
    "print(\"Tuned Random Forest Regressor Cross-Validation Performance:\")\n",
    "print(\"Cross-Validation RMSE: Mean =\", cv_rmse.mean())\n",
    "print(\"Cross-Validation MAE: Mean =\", cv_mae.mean())\n",
    "print(\"Cross-Validation R^2: Mean =\", cv_r2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 20, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 300, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "print(best_random_forest_model.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Best parameters: {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default xgboost model\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=30)\n",
    "\n",
    "cv_rmse = np.sqrt(-cross_val_score(xgb_model, X, y, cv=rkf, scoring='neg_mean_squared_error'))\n",
    "cv_mae = -cross_val_score(xgb_model, X, y, cv=rkf, scoring='neg_mean_absolute_error')\n",
    "cv_r2 = cross_val_score(xgb_model, X, y, cv=rkf, scoring='r2')\n",
    "\n",
    "print(\"XGBoost Regressor Cross-Validation Performance:\")\n",
    "print(\"Cross-Validation RMSE: Mean =\", cv_rmse.mean())\n",
    "print(\"Cross-Validation MAE: Mean =\", cv_mae.mean())\n",
    "print(\"Cross-Validation R^2: Mean =\", cv_r2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb_model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 150 folds for each of 20 candidates, totalling 3000 fits\n",
      "Best Parameters: {'subsample': 0.9, 'reg_lambda': 1.5, 'reg_alpha': 0.1, 'n_estimators': 100, 'min_child_weight': 1, 'max_depth': 3, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 0.8}\n",
      "Best Cross-validated R^2: 0.822994471473593\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  \n",
    "    'learning_rate': [0.01, 0.1, 0.2],  \n",
    "    'max_depth': [3, 5, 7],  \n",
    "    'min_child_weight': [1, 3, 5],  \n",
    "    'subsample': [0.8, 0.9, 1.0],  \n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],  \n",
    "    'gamma': [0, 0.1, 0.3],  \n",
    "    'reg_alpha': [0, 0.1, 0.5],  \n",
    "    'reg_lambda': [1, 1.5, 2],\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=best_xgb_model, param_distributions=param_grid, \n",
    "                                   n_iter=20, scoring='r2', \n",
    "                                   cv=rkf, n_jobs=-1, random_state=42, verbose=1)\n",
    "\n",
    "random_search.fit(X, y)\n",
    "\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best Cross-validated R^2:\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned XGBoost Regressor Cross-Validation Performance:\n",
      "Cross-Validation RMSE: Mean = 351398.5454409818\n",
      "Cross-Validation MAE: Mean = 129679.32760693309\n",
      "Cross-Validation R^2: Mean = 0.812226392694275\n"
     ]
    }
   ],
   "source": [
    "best_xgb_model = random_search.best_estimator_\n",
    "\n",
    "cv_rmse = np.sqrt(-cross_val_score(best_xgb_model, X, y, cv=rkf, scoring='neg_mean_squared_error'))\n",
    "cv_mae = -cross_val_score(best_xgb_model, X, y, cv=rkf, scoring='neg_mean_absolute_error')\n",
    "cv_r2 = cross_val_score(best_xgb_model, X, y, cv=rkf, scoring='r2')\n",
    "\n",
    "print(\"Tuned XGBoost Regressor Cross-Validation Performance:\")\n",
    "print(\"Cross-Validation RMSE: Mean =\", cv_rmse.mean())\n",
    "print(\"Cross-Validation MAE: Mean =\", cv_mae.mean())\n",
    "print(\"Cross-Validation R^2: Mean =\", cv_r2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'reg:squarederror', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.8, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': 0, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.1, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 3, 'max_leaves': None, 'min_child_weight': 1, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 100, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': None, 'reg_alpha': 0.1, 'reg_lambda': 1.5, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.9, 'tree_method': None, 'validate_parameters': None, 'verbosity': None}\n"
     ]
    }
   ],
   "source": [
    "print(best_xgb_model.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost Parameters: {'subsample': 0.9, 'reg_lambda': 1.5, 'reg_alpha': 0.1, 'n_estimators': 100, 'min_child_weight': 1, 'max_depth': 3, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 0.8}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For saving a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'model/example.pkl'\n",
    "\n",
    "# Open the file to save the model\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(xgb_model, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
